{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antndlcrx/Intro-to-Python-DPIR/blob/main/Week%203/W3_pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMvFSiSoRST6"
      },
      "source": [
        "<img src=\"https://cdn.githubraw.com/antndlcrx/Intro-to-Python-DPIR/main/images/logo_dpir.png?raw=true:,  width=35\" alt=\"My Image\" width=175>  \n",
        "\n",
        "# **Getting Familiar with Pandas**\n",
        "\n",
        " <img src=\"https://cdn.githubraw.com/antndlcrx/Intro-to-Python-DPIR/main/images/W3/pandas_logo.png?raw=true:,  width=25\" alt=\"My Image\" width=175>\n",
        "\n",
        " The material below is based on [Pandas Data Science Handbook, Data manipulation with Pandas Section](https://learning.oreilly.com/library/view/python-data-science/9781098121211/ch20.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "learning_objectives"
      },
      "source": [
        "## **What You'll Learn**\n",
        "\n",
        "By the end of this session, you will be able to:\n",
        "\n",
        "1. Use **dictionaries** to organise key-value data\n",
        "2. Create and inspect **DataFrames** ‚Äî the core Pandas data structure\n",
        "3. **Select and filter** data using `loc`, `iloc`, and boolean conditions\n",
        "4. **Load real datasets** from CSV files and explore them\n",
        "5. Use **groupby** to compute statistics by category\n",
        "6. **Combine datasets** using merge\n",
        "\n",
        "**Why Pandas matters:** DataFrames are the standard format for tabular data in Python. Every data science library: sklearn for machine learning, statsmodels for regression, seaborn for visualisation expects Pandas DataFrames. Master this, and you unlock the entire Python data ecosystem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **How This Connects**\n",
        "\n",
        "Pandas is where Python becomes practical for data analysis:\n",
        "```\n",
        "Week 1: Python fundamentals (variables, loops, functions)\n",
        "    ‚Üì\n",
        "Week 2: NumPy (arrays, vectorisation, broadcasting)\n",
        "    ‚Üì\n",
        "Week 3: Pandas (DataFrames, real-world data)  ‚Üê YOU ARE HERE\n",
        "    ‚Üì\n",
        "Week 4: Visualisation (plotting your DataFrames)\n",
        "    ‚Üì\n",
        "Week 5: Python Classes\n",
        "    ‚Üì\n",
        "Week 6: scikit-learn (ML models expect DataFrames or arrays)\n",
        "\n",
        "```\n",
        "\n",
        "Everything you learned in Week 2 transfers directly:\n",
        "- **Indexing/slicing** ‚Üí selecting rows and columns\n",
        "- **Boolean indexing** ‚Üí filtering data with conditions  \n",
        "- **Aggregations** (mean, sum, std) ‚Üí same methods, now on columns\n",
        "- **Vectorised operations** ‚Üí column arithmetic without loops\n",
        "\n",
        "The key upgrade: Pandas adds **labels**. Instead of remembering that column 3 is GDP, you write `df['gdp']`. Instead of row 42, you write `df.loc['France']`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "As7xBLhFRc52"
      },
      "source": [
        "## **1**.&nbsp; **Why do we need Pandas?**\n",
        "\n",
        "Last week you learned NumPy for numerical arrays. But real-world data is messier: mixed types (numbers, text, dates), named columns, missing values. That's what Pandas handles.\n",
        "\n",
        "Pandas offers two core data structures:\n",
        "- **Series**: A one-dimensional labelled array (like a single column)\n",
        "- **DataFrame**: A two-dimensional labelled table (like a spreadsheet)\n",
        "\n",
        "Pandas integrates seamlessly with NumPy, Matplotlib, and scikit-learn ‚Äî it's the glue that connects everything."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xsnPQdjJX7A"
      },
      "outputs": [],
      "source": [
        "import pandas as pd  # the classic alias\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dict_intro"
      },
      "source": [
        "## **2**.&nbsp; **Dictionaries: The Bridge to DataFrames**\n",
        "\n",
        "Before we create DataFrames, we need to understand **dictionaries** ‚Äî Python's built-in structure for storing **key-value pairs**. Dictionaries are everywhere in Python: configuration files, API responses, function arguments, and crucially, they're the most common way to create DataFrames.\n",
        "\n",
        "A dictionary maps unique **keys** to **values**:\n",
        "\n",
        "```python\n",
        "my_dict = {\"key1\": value1, \"key2\": value2}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dict_create"
      },
      "outputs": [],
      "source": [
        "# Creating a dictionary\n",
        "country_data = {\n",
        "    \"name\": \"France\",\n",
        "    \"population\": 67,  # millions\n",
        "    \"gdp_pc\": 42000,\n",
        "    \"continent\": \"Europe\",\n",
        "}\n",
        "\n",
        "country_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dict_access"
      },
      "outputs": [],
      "source": [
        "# Accessing values by key\n",
        "print(country_data[\"name\"])\n",
        "print(country_data[\"population\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dict_modify"
      },
      "outputs": [],
      "source": [
        "# Adding and modifying entries\n",
        "country_data[\"capital\"] = \"Paris\"  # add new key\n",
        "country_data[\"population\"] = 68  # update existing key\n",
        "country_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dict_methods"
      },
      "source": [
        "### **Useful Dictionary Methods**\n",
        "\n",
        "| Method | Description | Example |\n",
        "|--------|-------------|--------|\n",
        "| `dict.keys()` | All keys | `country_data.keys()` |\n",
        "| `dict.values()` | All values | `country_data.values()` |\n",
        "| `dict.items()` | Key-value pairs | `country_data.items()` |\n",
        "| `dict.get(key)` | Safe access (no error if missing) | `country_data.get(\"capital\")` |\n",
        "| `dict.pop(key)` | Remove and return value | `country_data.pop(\"capital\")` |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dict_methods_demo"
      },
      "outputs": [],
      "source": [
        "print(list(country_data.keys()))\n",
        "print(list(country_data.values()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dict_comprehension"
      },
      "source": [
        "### **Dictionary Comprehensions**\n",
        "\n",
        "Just like list comprehensions, you can create dictionaries dynamically:\n",
        "\n",
        "```python\n",
        "{key_expression: value_expression for item in iterable}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = [i for i in range(7)]\n",
        "\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dict_comp_demo"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary of squares\n",
        "squares = {x: x**2 for x in range(1, 6)}\n",
        "print(squares)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zip_intro"
      },
      "source": [
        "### **The `zip()` Function**\n",
        "\n",
        "`zip()` pairs elements from multiple lists ‚Äî very useful for creating dictionaries from parallel lists:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zip_demo"
      },
      "outputs": [],
      "source": [
        "countries = [\"UK\", \"France\", \"Germany\"]\n",
        "populations = [67, 68, 83]\n",
        "\n",
        "# Zip them together\n",
        "paired = list(zip(countries, populations))\n",
        "print(paired)\n",
        "\n",
        "# Convert to dictionary\n",
        "pop_dict = dict(zip(countries, populations))\n",
        "print(pop_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exercise_1_header"
      },
      "source": [
        "---\n",
        "### ‚úèÔ∏è **Exercise 1: Working with Dictionaries** (~5 min)\n",
        "\n",
        "Dictionaries will be your primary tool for creating DataFrames. Let's practice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exercise_1"
      },
      "outputs": [],
      "source": [
        "# Exercise 1: Dictionaries\n",
        "\n",
        "# 1a) Create a dictionary called `university` with keys: \"name\", \"city\", \"students\", \"founded\"\n",
        "#     Fill in values for Oxford (or your university)\n",
        "university = {\n",
        "    \"name\": \"Oxford\",\n",
        "    \"city\": \"Oxford\",\n",
        "    \"students\": 26000,\n",
        "    \"founded\": 1096,\n",
        "}\n",
        "\n",
        "\n",
        "# 1b) Access and print just the number of students\n",
        "print(university[\"students\"])\n",
        "\n",
        "# 1c) Add a new key \"ranking\" with a value\n",
        "university[\"ranking\"] = 1\n",
        "\n",
        "# 1d) Using zip(), create a dictionary mapping these EU countries to their EU join year:\n",
        "#     countries: [\"France\", \"Germany\", \"Spain\", \"Poland\"]\n",
        "#     years: [1957, 1957, 1986, 2004]\n",
        "\n",
        "eu_countries = [\"France\", \"Germany\", \"Spain\", \"Poland\"]\n",
        "join_years = [1957, 1957, 1986, 2004]\n",
        "\n",
        "eu_dict = dict(zip(eu_countries, join_years))\n",
        "\n",
        "# 1e) ‚≠ê Create a dictionary comprehension that maps numbers 1-5 to their cubes\n",
        "#     Expected: {1: 1, 2: 8, 3: 27, 4: 64, 5: 125}\n",
        "cubes = {x: x**3 for x in range(1, 6)}\n",
        "print(cubes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dataframe_intro"
      },
      "source": [
        "## **3**.&nbsp; **Creating DataFrames**\n",
        "\n",
        "A **DataFrame** is a 2D table with labelled rows and columns. The most common way to create one is from a **dictionary of lists** ‚Äî each key becomes a column name, each list becomes the column data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df_from_dict"
      },
      "outputs": [],
      "source": [
        "# Dictionary of lists ‚Üí DataFrame\n",
        "data = {\n",
        "    \"country\": [\"UK\", \"France\", \"Germany\", \"Spain\"],\n",
        "    \"population\": [67, 68, 83, 47],  # millions\n",
        "    \"gdp_pc\": [42000, 40000, 46000, 30000],  # USD\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df_index_note"
      },
      "source": [
        "Notice Pandas automatically created a numeric index (0, 1, 2, 3). We can set a meaningful index:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df_set_index"
      },
      "outputs": [],
      "source": [
        "# Set country as the index\n",
        "df = df.set_index(\"country\")\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df_attributes"
      },
      "source": [
        "### **DataFrame Attributes**\n",
        "\n",
        "DataFrames have useful attributes to inspect their structure:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df_attributes_demo"
      },
      "outputs": [],
      "source": [
        "print(\"Shape:\", df.shape)  # (rows, columns)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "print(\"Index:\", df.index.tolist())\n",
        "print(\"Data types:\\n\", df.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df_new_col"
      },
      "source": [
        "### **Creating Columns from Calculations**\n",
        "\n",
        "You can create new columns using arithmetic on existing ones, just like NumPy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df_new_col_demo"
      },
      "outputs": [],
      "source": [
        "# Create a new column: total GDP (billions)\n",
        "df[\"gdp_total\"] = df[\"population\"] * df[\"gdp_pc\"] / 1000\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exercise_2_header"
      },
      "source": [
        "---\n",
        "### ‚úèÔ∏è **Exercise 2: Create and Modify a DataFrame** (~5 min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exercise_2"
      },
      "outputs": [],
      "source": [
        "# Exercise 2: Build a DataFrame\n",
        "\n",
        "# 2a) Create a DataFrame called `cities` with this data:\n",
        "#     City: London, Birmingham, Manchester, Leeds, Glasgow\n",
        "#     Population (thousands): 8982, 1141, 553, 793, 635\n",
        "#     Area (sq km): 1572, 268, 116, 552, 175\n",
        "cities = {\n",
        "    \"City\": [\"London\", \"Birmingham\", \"Manchester\", \"Leeds\", \"Glasgow\"],\n",
        "    \"Population\": [8982, 1141, 553, 793, 635],  # thousands\n",
        "    \"Area\": [1572, 268, 116, 552, 175],  # sq km\n",
        "}\n",
        "\n",
        "cities = pd.DataFrame(cities)\n",
        "cities\n",
        "\n",
        "# 2b) Set the city name as the index\n",
        "cities = cities.set_index(\"City\")\n",
        "\n",
        "# 2c) Add a column \"density\" = population / area\n",
        "cities[\"Density\"] = cities[\"Population\"] / cities[\"Area\"]\n",
        "\n",
        "\n",
        "# 2d) Print the shape and column names\n",
        "print(\"Shape:\", cities.shape)\n",
        "print(\"Columns:\", cities.columns.tolist())\n",
        "\n",
        "# 2e) ‚≠ê Add a column \"size_category\": \"large\" if population > 1000, else \"medium\"\n",
        "cities[\"Size_Category\"] = np.where(cities[\"Population\"] > 1000, \"large\", \"medium\")\n",
        "print(cities[\"Size_Category\"].tolist())\n",
        "#     Hint: use np.where(condition, value_if_true, value_if_false)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loc_iloc_intro"
      },
      "source": [
        "## **4**.&nbsp; **Selecting Data: `loc` and `iloc`**\n",
        "\n",
        "Selecting data from DataFrames is a core skill. Pandas offers two main indexers:\n",
        "\n",
        "| Indexer | Selects by | Example |\n",
        "|---------|-----------|--------|\n",
        "| `df.loc[]` | **Labels** (row/column names) | `df.loc[\"UK\", \"gdp_pc\"]` |\n",
        "| `df.iloc[]` | **Integer position** (0, 1, 2...) | `df.iloc[0, 1]` |\n",
        "\n",
        "**Rule of thumb:** Use `loc` for labels, `iloc` for positions. Be explicit!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df_reminder"
      },
      "outputs": [],
      "source": [
        "# Reminder of our DataFrame\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "select_cols"
      },
      "source": [
        "### **Selecting Columns**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "select_col_single"
      },
      "outputs": [],
      "source": [
        "# Single column (returns a Series)\n",
        "df[\"population\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "select_col_multi"
      },
      "outputs": [],
      "source": [
        "# Multiple columns (returns a DataFrame)\n",
        "df[[\"population\", \"gdp_pc\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "select_loc"
      },
      "source": [
        "### **Selecting Rows with `loc` (by label)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loc_single"
      },
      "outputs": [],
      "source": [
        "# Single row\n",
        "df.loc[\"France\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loc_multi"
      },
      "outputs": [],
      "source": [
        "# Multiple rows\n",
        "df.loc[[\"UK\", \"Germany\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loc_both"
      },
      "outputs": [],
      "source": [
        "# Rows AND columns\n",
        "df.loc[\"France\", \"gdp_pc\"]              # single value\n",
        "df.loc[[\"UK\", \"France\"], [\"population\", \"gdp_pc\"]]  # subset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "select_iloc"
      },
      "source": [
        "### **Selecting Rows with `iloc` (by position)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iloc_single"
      },
      "outputs": [],
      "source": [
        "# First row (position 0)\n",
        "df.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iloc_slice"
      },
      "outputs": [],
      "source": [
        "# First 2 rows, first 2 columns\n",
        "df.iloc[0:2, 0:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boolean_filter"
      },
      "source": [
        "### **Boolean Filtering**\n",
        "\n",
        "Filter rows where a condition is True ‚Äî this is extremely common:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "filter_single"
      },
      "outputs": [],
      "source": [
        "# Countries with population > 60 million\n",
        "df[df[\"population\"] > 60]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "filter_multi"
      },
      "outputs": [],
      "source": [
        "# Multiple conditions: use & (and), | (or), with parentheses!\n",
        "df[(df[\"population\"] > 50) & (df[\"gdp_pc\"] > 35000)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exercise_3_header"
      },
      "source": [
        "---\n",
        "### ‚úèÔ∏è **Exercise 3: Selecting and Filtering** (~8 min)\n",
        "\n",
        "Use the `cities` DataFrame you created in Exercise 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exercise_3"
      },
      "outputs": [],
      "source": [
        "# Exercise 3: Selection and Filtering\n",
        "\n",
        "# First, recreate cities if needed:\n",
        "cities = pd.DataFrame({\n",
        "    \"population\": [8982, 1141, 553, 793, 635],\n",
        "    \"area\": [1572, 268, 116, 552, 175]\n",
        "}, index=[\"London\", \"Birmingham\", \"Manchester\", \"Leeds\", \"Glasgow\"])\n",
        "cities[\"density\"] = cities[\"population\"] / cities[\"area\"]\n",
        "\n",
        "# 3a) Select just the population column\n",
        "\n",
        "\n",
        "# 3b) Select population and density for Birmingham only (use loc)\n",
        "\n",
        "\n",
        "# 3c) Select the first 3 rows using iloc\n",
        "\n",
        "\n",
        "# 3d) Filter to cities with population > 700 thousand\n",
        "\n",
        "\n",
        "# 3e) Filter to cities with density > 4 AND area > 200\n",
        "\n",
        "\n",
        "# 3f) ‚≠ê Select population for [\"London\", \"Glasgow\"] using loc,\n",
        "#     then calculate their combined population\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loading_data"
      },
      "source": [
        "## **5**.&nbsp; **Loading and Exploring Real Data**\n",
        "\n",
        "In practice, you'll load data from files rather than typing it in. Let's work with a real dataset: the **Quality of Government** data, a collection of political and economic indicators for countries worldwide.\n",
        "\n",
        "üìö [QOG Institute Website](https://www.gu.se/en/quality-government)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "git_clone"
      },
      "outputs": [],
      "source": [
        "# Clone the course repository to access datasets\n",
        "!git clone https://github.com/antndlcrx/Intro-to-Python-DPIR.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_qog"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "qog = pd.read_csv(\"/content/Intro-to-Python-DPIR/datasets/qog2022.csv\")\n",
        "\n",
        "# First look\n",
        "qog.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qog_variables"
      },
      "source": [
        "### **Dataset Variables**\n",
        "\n",
        "| Variable | Description |\n",
        "|----------|-------------|\n",
        "| **country** | Country name |\n",
        "| **region** | Continent |\n",
        "| **iso3c** | Country code |\n",
        "| **perc_wip** | % women in parliament |\n",
        "| **gdp_pc** | GDP per capita (USD) |\n",
        "| **corruption** | Corruption index (higher = more corrupt) |\n",
        "| **hdi** | Human Development Index |\n",
        "| **glob_index** | Globalisation index |\n",
        "| **fh_polity** | Freedom House democracy score (0-10) |\n",
        "| **fh_status** | Freedom status (Free, Partly Free, Not Free) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "explore_methods"
      },
      "source": [
        "### **Exploratory Methods**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qog_shape"
      },
      "outputs": [],
      "source": [
        "# Shape: how many rows and columns?\n",
        "qog.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qog_info"
      },
      "outputs": [],
      "source": [
        "# Info: column types and missing values\n",
        "qog.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qog_describe"
      },
      "outputs": [],
      "source": [
        "# Describe: summary statistics for numeric columns\n",
        "qog.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qog_value_counts"
      },
      "outputs": [],
      "source": [
        "# Value counts: frequency of categorical values\n",
        "qog[\"fh_status\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qog_unique"
      },
      "outputs": [],
      "source": [
        "# Unique values\n",
        "qog[\"region\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exercise_4_header"
      },
      "source": [
        "---\n",
        "### ‚úèÔ∏è **Exercise 4: Explore the QOG Dataset** (~8 min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exercise_4"
      },
      "outputs": [],
      "source": [
        "# Exercise 4: Exploring QOG\n",
        "\n",
        "# 4a) How many countries are in the dataset?\n",
        "\n",
        "\n",
        "# 4b) What is the mean GDP per capita across all countries?\n",
        "\n",
        "\n",
        "# 4c) How many countries are in each region? (use value_counts)\n",
        "\n",
        "\n",
        "# 4d) Filter to European countries only. How many are there?\n",
        "\n",
        "\n",
        "# 4e) Filter to countries that are both \"Free\" AND have HDI > 0.9\n",
        "#     How many countries meet both criteria?\n",
        "\n",
        "\n",
        "# 4f) ‚≠ê What are the 5 most corrupt countries? (hint: sort_values, tail or head)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "groupby_intro"
      },
      "source": [
        "## **6**.&nbsp; **Groupby: Split-Apply-Combine**\n",
        "\n",
        "One of Pandas' most powerful features is `groupby`, which lets you compute statistics *by category*. It follows a **split-apply-combine** pattern:\n",
        "\n",
        "1. **Split** the data by some grouping variable\n",
        "2. **Apply** a function (mean, sum, count, etc.) to each group\n",
        "3. **Combine** the results into a new DataFrame\n",
        "\n",
        "<img src=\"https://cdn.githubraw.com/antndlcrx/Intro-to-Python-DPIR/main/images/W3/groupby.png?raw=true:,  width=150\" alt=\"My Image\" width=475>\n",
        "\n",
        "[Img source: Pandas Data Science Handbook, Ch 20.](https://learning.oreilly.com/library/view/python-data-science/9781098121211/ch20.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "groupby_basic"
      },
      "outputs": [],
      "source": [
        "# Mean GDP by region\n",
        "qog.groupby(\"region\")[\"gdp_pc\"].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "groupby_agg"
      },
      "outputs": [],
      "source": [
        "# Multiple statistics\n",
        "qog.groupby(\"region\")[\"gdp_pc\"].agg([\"mean\", \"median\", \"std\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "groupby_multi"
      },
      "outputs": [],
      "source": [
        "# Group by multiple columns\n",
        "qog.groupby([\"region\", \"fh_status\"])[\"gdp_pc\"].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "groupby_multi_cols"
      },
      "outputs": [],
      "source": [
        "# Multiple columns, multiple stats\n",
        "qog.groupby(\"fh_status\")[[\"gdp_pc\", \"hdi\", \"corruption\"]].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "merge_intro"
      },
      "source": [
        "## **7**.&nbsp; **Combining Datasets: Merge**\n",
        "\n",
        "Real-world analysis often requires combining data from multiple sources. `pd.merge()` joins DataFrames based on shared columns, similar to SQL joins or Excel VLOOKUP.\n",
        "\n",
        "**Join types:**\n",
        "| Type | Keeps |\n",
        "|------|-------|\n",
        "| `inner` | Only matching rows (default) |\n",
        "| `left` | All rows from left DataFrame |\n",
        "| `right` | All rows from right DataFrame |\n",
        "| `outer` | All rows from both |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "merge_setup"
      },
      "outputs": [],
      "source": [
        "# Example: Two DataFrames with a shared column\n",
        "df1 = pd.DataFrame({\n",
        "    \"country\": [\"UK\", \"France\", \"Germany\"],\n",
        "    \"population\": [67, 68, 83]\n",
        "})\n",
        "\n",
        "df2 = pd.DataFrame({\n",
        "    \"country\": [\"UK\", \"France\", \"Spain\"],\n",
        "    \"capital\": [\"London\", \"Paris\", \"Madrid\"]\n",
        "})\n",
        "\n",
        "print(\"df1:\")\n",
        "print(df1)\n",
        "print(\"\\ndf2:\")\n",
        "print(df2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "merge_inner"
      },
      "outputs": [],
      "source": [
        "# Inner merge: only countries in BOTH DataFrames\n",
        "pd.merge(df1, df2, on=\"country\", how=\"inner\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "merge_left"
      },
      "outputs": [],
      "source": [
        "# Left merge: keep all countries from df1\n",
        "pd.merge(df1, df2, on=\"country\", how=\"left\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "merge_outer"
      },
      "outputs": [],
      "source": [
        "# Outer merge: keep all countries from both\n",
        "pd.merge(df1, df2, on=\"country\", how=\"outer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "merge_nan_note"
      },
      "source": [
        "Notice the `NaN` values. These appear when a country exists in one DataFrame but not the other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exercise_5_header"
      },
      "source": [
        "---\n",
        "### ‚úèÔ∏è **Exercise 5: Merge and Groupby** (~8 min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exercise_5"
      },
      "outputs": [],
      "source": [
        "# Exercise 5: Combining data\n",
        "\n",
        "# Here's election data from two rounds:\n",
        "round1 = pd.DataFrame({\n",
        "    \"candidate\": [\"Alice\", \"Bob\", \"Carol\"],\n",
        "    \"votes_r1\": [3500, 4200, 2900],\n",
        "    \"party\": [\"Red\", \"Blue\", \"Red\"]\n",
        "})\n",
        "\n",
        "round2 = pd.DataFrame({\n",
        "    \"candidate\": [\"Alice\", \"Bob\", \"Dave\"],\n",
        "    \"votes_r2\": [4100, 3800, 5000]\n",
        "})\n",
        "\n",
        "# 5a) Merge round1 and round2 using an inner join. Who appears in both rounds?\n",
        "\n",
        "\n",
        "# 5b) Merge using a left join (keep all candidates from round1)\n",
        "#     Who has NaN for votes_r2?\n",
        "\n",
        "\n",
        "# 5c) Using the left-merged result, create a column \"total_votes\" = votes_r1 + votes_r2\n",
        "#     (Note: NaN + number = NaN)\n",
        "\n",
        "\n",
        "# 5d) Group the inner-merged result by party and calculate total votes_r1 per party\n",
        "\n",
        "\n",
        "# 5e) ‚≠ê Merge round1 and round2 with outer join, then fill NaN values with 0\n",
        "#     Hint: use .fillna(0) on the result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "capstone_header"
      },
      "source": [
        "---\n",
        "## **8**.&nbsp; **Bringing It All Together: Democracy and Development Analysis**\n",
        "\n",
        "Now let's put everything together. You'll conduct a mini-analysis exploring the relationship between democracy and development using the QOG dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exercise_6_capstone"
      },
      "outputs": [],
      "source": [
        "# Exercise 6: Democracy and Development\n",
        "# Work through each step to build a complete analysis.\n",
        "\n",
        "# 6a) Load the QOG data (if not already loaded)\n",
        "qog = pd.read_csv(\"/content/Intro-to-Python-DPIR/datasets/qog2022.csv\")\n",
        "\n",
        "# 6b) How many countries are \"Free\", \"Partly Free\", and \"Not Free\"?\n",
        "\n",
        "\n",
        "# 6c) Calculate mean GDP per capita by freedom status.\n",
        "#     Which status has the highest average GDP?\n",
        "\n",
        "\n",
        "# 6d) Filter to only African and Asian countries.\n",
        "#     Store in a variable called `regional`.\n",
        "\n",
        "\n",
        "# 6e) In `regional`, calculate mean HDI by region AND freedom status.\n",
        "#     Which region-status combination has the lowest HDI?\n",
        "\n",
        "\n",
        "# 6f) Create a new column in `regional` called \"dev_level\":\n",
        "#     - \"high\" if HDI >= 0.8\n",
        "#     - \"medium\" if 0.6 <= HDI < 0.8\n",
        "#     - \"low\" if HDI < 0.6\n",
        "#     Hint: use np.select([conditions], [choices], default=...)\n",
        "\n",
        "\n",
        "# 6g) Count how many countries fall into each dev_level, grouped by region.\n",
        "\n",
        "\n",
        "# 6h) Load the PPI (Parliamentary Powers Index) data and merge with qog:\n",
        "ppi = pd.read_csv(\"/content/Intro-to-Python-DPIR/datasets/ppi.csv\")\n",
        "# Merge keeping all qog countries (left join)\n",
        "\n",
        "\n",
        "# 6i) Calculate the correlation between parliamentary power (ppi) and\n",
        "#     women in parliament (perc_wip). What do you find?\n",
        "#     Hint: df[[\"col1\", \"col2\"]].corr()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reference_table"
      },
      "source": [
        "---\n",
        "## **Quick Reference**\n",
        "\n",
        "| Task | Code |\n",
        "|------|------|\n",
        "| Create DataFrame | `pd.DataFrame({\"col1\": [...], \"col2\": [...]})` |\n",
        "| Select column | `df[\"column\"]` |\n",
        "| Select multiple columns | `df[[\"col1\", \"col2\"]]` |\n",
        "| Select by label | `df.loc[\"row_label\"]` or `df.loc[\"row\", \"col\"]` |\n",
        "| Select by position | `df.iloc[0]` or `df.iloc[0, 1]` |\n",
        "| Filter rows | `df[df[\"col\"] > value]` |\n",
        "| Multiple conditions | `df[(cond1) & (cond2)]` |\n",
        "| Load CSV | `pd.read_csv(\"file.csv\")` |\n",
        "| First n rows | `df.head(n)` |\n",
        "| Summary stats | `df.describe()` |\n",
        "| Value counts | `df[\"col\"].value_counts()` |\n",
        "| Groupby | `df.groupby(\"col\")[\"target\"].mean()` |\n",
        "| Merge | `pd.merge(df1, df2, on=\"col\", how=\"left\")` |\n",
        "| Save to CSV | `df.to_csv(\"file.csv\", index=False)` |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "homework"
      },
      "source": [
        "---\n",
        "## **Homework**\n",
        "\n",
        "1. Complete any exercises you didn't finish in class\n",
        "2. Extend the Exercise 6 analysis:\n",
        "   - Pick 2 additional variables from QOG\n",
        "   - Formulate a research question (e.g., \"Do more globalised countries have less corruption?\")\n",
        "   - Use filtering and groupby to explore your question\n",
        "3. Read: [Pandas Getting Started Tutorial](https://pandas.pydata.org/docs/getting_started/intro_tutorials/index.html)\n",
        "\n",
        "---\n",
        "## **Resources**\n",
        "\n",
        "- [Pandas Documentation](https://pandas.pydata.org/docs/)\n",
        "- [Python Data Science Handbook, Ch 3](https://jakevdp.github.io/PythonDataScienceHandbook/03.00-introduction-to-pandas.html)\n",
        "- [QOG Institute](https://www.gu.se/en/quality-government) ‚Äî explore the full dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "extra_concat"
      },
      "source": [
        "---\n",
        "## **Extra: Concatenating DataFrames**\n",
        "\n",
        "*For fast finishers or self-study*\n",
        "\n",
        "While `merge` combines DataFrames horizontally (adding columns), `concat` stacks them vertically (adding rows) or horizontally:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "concat_vertical"
      },
      "outputs": [],
      "source": [
        "# Vertical concatenation: stacking rows\n",
        "df_a = pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]})\n",
        "df_b = pd.DataFrame({\"A\": [5, 6], \"B\": [7, 8]})\n",
        "\n",
        "pd.concat([df_a, df_b], ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "extra_missing"
      },
      "source": [
        "---\n",
        "## **Extra: Handling Missing Data**\n",
        "\n",
        "*For fast finishers or self-study*\n",
        "\n",
        "Pandas uses `NaN` (Not a Number) for missing values. Key methods:\n",
        "\n",
        "| Method | Description |\n",
        "|--------|-------------|\n",
        "| `df.isna()` | Boolean mask of missing values |\n",
        "| `df.dropna()` | Remove rows with missing values |\n",
        "| `df.fillna(value)` | Replace missing values |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "missing_count"
      },
      "outputs": [],
      "source": [
        "# Count missing values per column\n",
        "qog.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "missing_drop"
      },
      "outputs": [],
      "source": [
        "# Drop rows where gdp_pc is missing\n",
        "qog_clean = qog.dropna(subset=[\"gdp_pc\"])\n",
        "print(f\"Before: {len(qog)}, After: {len(qog_clean)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "missing_fill"
      },
      "outputs": [],
      "source": [
        "# Fill missing GDP with median\n",
        "qog[\"gdp_pc_filled\"] = qog[\"gdp_pc\"].fillna(qog[\"gdp_pc\"].median())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "solutions_header"
      },
      "source": [
        "---\n",
        "## **Solutions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "solutions_1"
      },
      "outputs": [],
      "source": [
        "#@title Exercise 1 Solutions\n",
        "\n",
        "# 1a)\n",
        "university = {\n",
        "    \"name\": \"Oxford\",\n",
        "    \"city\": \"Oxford\",\n",
        "    \"students\": 26000,\n",
        "    \"founded\": 1096\n",
        "}\n",
        "\n",
        "# 1b)\n",
        "print(university[\"students\"])\n",
        "\n",
        "# 1c)\n",
        "university[\"ranking\"] = 1\n",
        "\n",
        "# 1d)\n",
        "countries = [\"France\", \"Germany\", \"Spain\", \"Poland\"]\n",
        "years = [1957, 1957, 1986, 2004]\n",
        "eu_join = dict(zip(countries, years))\n",
        "print(eu_join)\n",
        "\n",
        "# 1e)\n",
        "cubes = {x: x**3 for x in range(1, 6)}\n",
        "print(cubes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "solutions_2"
      },
      "outputs": [],
      "source": [
        "#@title Exercise 2 Solutions\n",
        "\n",
        "# 2a)\n",
        "cities = pd.DataFrame({\n",
        "    \"city\": [\"London\", \"Birmingham\", \"Manchester\", \"Leeds\", \"Glasgow\"],\n",
        "    \"population\": [8982, 1141, 553, 793, 635],\n",
        "    \"area\": [1572, 268, 116, 552, 175]\n",
        "})\n",
        "\n",
        "# 2b)\n",
        "cities = cities.set_index(\"city\")\n",
        "\n",
        "# 2c)\n",
        "cities[\"density\"] = cities[\"population\"] / cities[\"area\"]\n",
        "\n",
        "# 2d)\n",
        "print(cities.shape)\n",
        "print(cities.columns.tolist())\n",
        "\n",
        "# 2e)\n",
        "cities[\"size_category\"] = np.where(cities[\"population\"] > 1000, \"large\", \"medium\")\n",
        "print(cities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "solutions_3"
      },
      "outputs": [],
      "source": [
        "#@title Exercise 3 Solutions\n",
        "\n",
        "# Recreate cities\n",
        "cities = pd.DataFrame({\n",
        "    \"population\": [8982, 1141, 553, 793, 635],\n",
        "    \"area\": [1572, 268, 116, 552, 175]\n",
        "}, index=[\"London\", \"Birmingham\", \"Manchester\", \"Leeds\", \"Glasgow\"])\n",
        "cities[\"density\"] = cities[\"population\"] / cities[\"area\"]\n",
        "\n",
        "# 3a)\n",
        "print(cities[\"population\"])\n",
        "\n",
        "# 3b)\n",
        "print(cities.loc[\"Birmingham\", [\"population\", \"density\"]])\n",
        "\n",
        "# 3c)\n",
        "print(cities.iloc[0:3])\n",
        "\n",
        "# 3d)\n",
        "print(cities[cities[\"population\"] > 700])\n",
        "\n",
        "# 3e)\n",
        "print(cities[(cities[\"density\"] > 4) & (cities[\"area\"] > 200)])\n",
        "\n",
        "# 3f)\n",
        "combined_pop = cities.loc[[\"London\", \"Glasgow\"], \"population\"].sum()\n",
        "print(f\"Combined population: {combined_pop}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "solutions_4"
      },
      "outputs": [],
      "source": [
        "#@title Exercise 4 Solutions\n",
        "\n",
        "qog = pd.read_csv(\"/content/Intro-to-Python-DPIR/datasets/qog2022.csv\")\n",
        "\n",
        "# 4a)\n",
        "print(f\"Number of countries: {len(qog)}\")\n",
        "\n",
        "# 4b)\n",
        "print(f\"Mean GDP per capita: {qog['gdp_pc'].mean():.2f}\")\n",
        "\n",
        "# 4c)\n",
        "print(qog[\"region\"].value_counts())\n",
        "\n",
        "# 4d)\n",
        "europe = qog[qog[\"region\"] == \"Europe\"]\n",
        "print(f\"European countries: {len(europe)}\")\n",
        "\n",
        "# 4e)\n",
        "free_developed = qog[(qog[\"fh_status\"] == \"Free\") & (qog[\"hdi\"] > 0.9)]\n",
        "print(f\"Free AND HDI > 0.9: {len(free_developed)}\")\n",
        "\n",
        "# 4f)\n",
        "most_corrupt = qog.sort_values(\"corruption\", ascending=False).head(5)\n",
        "print(most_corrupt[[\"country\", \"corruption\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "solutions_5"
      },
      "outputs": [],
      "source": [
        "#@title Exercise 5 Solutions\n",
        "\n",
        "round1 = pd.DataFrame({\n",
        "    \"candidate\": [\"Alice\", \"Bob\", \"Carol\"],\n",
        "    \"votes_r1\": [3500, 4200, 2900],\n",
        "    \"party\": [\"Red\", \"Blue\", \"Red\"]\n",
        "})\n",
        "\n",
        "round2 = pd.DataFrame({\n",
        "    \"candidate\": [\"Alice\", \"Bob\", \"Dave\"],\n",
        "    \"votes_r2\": [4100, 3800, 5000]\n",
        "})\n",
        "\n",
        "# 5a)\n",
        "inner = pd.merge(round1, round2, on=\"candidate\", how=\"inner\")\n",
        "print(\"Inner join:\")\n",
        "print(inner)\n",
        "\n",
        "# 5b)\n",
        "left = pd.merge(round1, round2, on=\"candidate\", how=\"left\")\n",
        "print(\"\\nLeft join:\")\n",
        "print(left)\n",
        "\n",
        "# 5c)\n",
        "left[\"total_votes\"] = left[\"votes_r1\"] + left[\"votes_r2\"]\n",
        "print(\"\\nWith total:\")\n",
        "print(left)\n",
        "\n",
        "# 5d)\n",
        "print(\"\\nVotes by party:\")\n",
        "print(inner.groupby(\"party\")[\"votes_r1\"].sum())\n",
        "\n",
        "# 5e)\n",
        "outer_filled = pd.merge(round1, round2, on=\"candidate\", how=\"outer\").fillna(0)\n",
        "print(\"\\nOuter join filled:\")\n",
        "print(outer_filled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "solutions_6"
      },
      "outputs": [],
      "source": [
        "#@title Exercise 6 (Capstone) Solutions\n",
        "\n",
        "# 6a)\n",
        "qog = pd.read_csv(\"/content/Intro-to-Python-DPIR/datasets/qog2022.csv\")\n",
        "\n",
        "# 6b)\n",
        "print(\"Freedom status counts:\")\n",
        "print(qog[\"fh_status\"].value_counts())\n",
        "\n",
        "# 6c)\n",
        "print(\"\\nMean GDP by freedom status:\")\n",
        "print(qog.groupby(\"fh_status\")[\"gdp_pc\"].mean().sort_values(ascending=False))\n",
        "\n",
        "# 6d)\n",
        "regional = qog[qog[\"region\"].isin([\"Africa\", \"Asia\"])].copy()\n",
        "print(f\"\\nAfrica + Asia countries: {len(regional)}\")\n",
        "\n",
        "# 6e)\n",
        "print(\"\\nMean HDI by region and freedom status:\")\n",
        "print(regional.groupby([\"region\", \"fh_status\"])[\"hdi\"].mean())\n",
        "\n",
        "# 6f)\n",
        "conditions = [\n",
        "    regional[\"hdi\"] >= 0.8,\n",
        "    (regional[\"hdi\"] >= 0.6) & (regional[\"hdi\"] < 0.8),\n",
        "    regional[\"hdi\"] < 0.6\n",
        "]\n",
        "choices = [\"high\", \"medium\", \"low\"]\n",
        "regional[\"dev_level\"] = np.select(conditions, choices, default=\"unknown\")\n",
        "\n",
        "# 6g)\n",
        "print(\"\\nDev level counts by region:\")\n",
        "print(regional.groupby([\"region\", \"dev_level\"]).size().unstack(fill_value=0))\n",
        "\n",
        "# 6h)\n",
        "ppi = pd.read_csv(\"/content/Intro-to-Python-DPIR/datasets/ppi.csv\")\n",
        "qog_ppi = pd.merge(qog, ppi, on=\"iso3c\", how=\"left\")\n",
        "print(f\"\\nMerged shape: {qog_ppi.shape}\")\n",
        "\n",
        "# 6i)\n",
        "print(\"\\nCorrelation between PPI and women in parliament:\")\n",
        "print(qog_ppi[[\"ppi\", \"perc_wip\"]].corr())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
